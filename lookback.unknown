#!/usr/bin/env python3
import argparse
import requests
import threading
import itertools
import time
import sys
import pyfiglet
from colorama import init, Fore, Style

init(autoreset=True)  

stop_spinner = False


def banner():
    ascii_banner = pyfiglet.figlet_format("LOOKBACK", font="standard")
    print(Fore.GREEN + ascii_banner)
    print(Fore.GREEN + "LookBack v1.0 - Fetch archived URLs")
    print(Fore.GREEN + "Made by C â€“ hey world... \n")


def spinner():
    for c in itertools.cycle(['|', '/', '-', '\\']):
        if stop_spinner:
            break
        sys.stdout.write(f'\r{Fore.YELLOW}[+] Fetching archived URLs... {c}')
        sys.stdout.flush()
        time.sleep(0.1)


def fetch_wayback_urls(domain, output_file=None):
    global stop_spinner
    url = f"https://web.archive.org/cdx/search/cdx?url=*.{domain}/*&collapse=urlkey&output=text&fl=original"
    
   
    spinner_thread = threading.Thread(target=spinner)
    spinner_thread.start()
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        urls = response.text.strip().split("\n")
    except requests.RequestException as e:
        stop_spinner = True
        print(f"\n{Fore.RED}[-] Error fetching URLs: {e}")
        return
    
    
    stop_spinner = True
    time.sleep(0.2)
    print("\r", end="")  
    
  
    clean_urls = []
    for u in urls:
        clean_url = u.strip()
        if clean_url:  
            clean_urls.append(clean_url)
            print(Fore.CYAN + "[+] " + clean_url)
    
   
    print(Fore.GREEN + f"\n[+] Found {len(clean_urls)} archived URLs for {domain}")
    print(Fore.GREEN + "[+] Done!\n")
    
   
    if output_file:
        with open(output_file, "w") as f:
            f.write("\n".join(clean_urls))
        print(Fore.GREEN + f"[+] Saved results to {output_file}")

# -------------------------
# Main
# -------------------------
if __name__ == "__main__":
    banner()
    parser = argparse.ArgumentParser(description="LookBack - Fetch archived URLs from the Wayback Machine.")
    parser.add_argument("-d", "--domain", required=True, help="Target domain (example.com)")
    parser.add_argument("-o", "--output", help="Save results to file")
    
    args = parser.parse_args()
    fetch_wayback_urls(args.domain, args.output)
